{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:38:28.703668Z",
     "start_time": "2025-10-02T08:38:28.694389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - Integer dtypes -> float64\n",
    "    - For object/string/categorical columns:\n",
    "        * If unique non-null values <= 15: keep as object\n",
    "        * If unique non-null values > 15: keep top 15, others -> \"Unknown\"\n",
    "    - Other dtypes left unchanged\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    for col in out.columns:\n",
    "        s = out[col]\n",
    "\n",
    "        # 1) Integers -> float64\n",
    "        if pd.api.types.is_integer_dtype(s):\n",
    "            out[col] = s.astype(\"float64\")\n",
    "            continue\n",
    "\n",
    "        # 2) Non-numeric categoricals/strings\n",
    "        is_cat_like = (\n",
    "            pd.api.types.is_object_dtype(s)\n",
    "            or isinstance(s.dtype, pd.CategoricalDtype)\n",
    "            or pd.api.types.is_string_dtype(s)\n",
    "        )\n",
    "        if is_cat_like:\n",
    "            n_unique = s.nunique(dropna=True)\n",
    "            if n_unique > 10:\n",
    "                top15 = s.value_counts(dropna=True).index[:10]\n",
    "                out[col] = s.where(s.isna() | s.isin(top15), \"Unknown\").astype(\"object\")\n",
    "            else:\n",
    "                out[col] = s.astype(\"object\")\n",
    "\n",
    "    return out"
   ],
   "id": "bd1a33c805b9f99b",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:38:29.008948Z",
     "start_time": "2025-10-02T08:38:28.745814Z"
    }
   },
   "cell_type": "code",
   "source": "df = process_df(pd.read_csv(\"../assets/online_news.csv\"))",
   "id": "c24bfc4788cd4c50",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:38:29.046190Z",
     "start_time": "2025-10-02T08:38:29.036899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import FIRM.base.fuzzy_data as fuzzy_data\n",
    "from FIRM.methods.AARFI import AARFI"
   ],
   "id": "400418abb5976510",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:38:29.167506Z",
     "start_time": "2025-10-02T08:38:29.078760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = df.copy()\n",
    "dataset = dataset.iloc[:, :20]\n",
    "# find integer columns and convert them to float\n",
    "int_cols = dataset.select_dtypes(include=['int']).columns\n",
    "dataset[int_cols] = dataset[int_cols].astype(float)\n",
    "fuzzy_dataset = fuzzy_data.FuzzyDataQuantiles('symmetric', dataset, 3, ['L', 'M', 'H'])"
   ],
   "id": "ab7f894745e23d72",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:38:29.227378Z",
     "start_time": "2025-10-02T08:38:29.200370Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.info",
   "id": "e2207fba19b794",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of         n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
       "0                 12.0              219.0          0.663594   \n",
       "1                  9.0              255.0          0.604743   \n",
       "2                  9.0              211.0          0.575130   \n",
       "3                  9.0              531.0          0.503788   \n",
       "4                 13.0             1072.0          0.415646   \n",
       "...                ...                ...               ...   \n",
       "39639             11.0              346.0          0.529052   \n",
       "39640             12.0              328.0          0.696296   \n",
       "39641             10.0              442.0          0.516355   \n",
       "39642              6.0              682.0          0.539493   \n",
       "39643             10.0              157.0          0.701987   \n",
       "\n",
       "        n_non_stop_words   n_non_stop_unique_tokens   num_hrefs  \\\n",
       "0                    1.0                   0.815385         4.0   \n",
       "1                    1.0                   0.791946         3.0   \n",
       "2                    1.0                   0.663866         3.0   \n",
       "3                    1.0                   0.665635         9.0   \n",
       "4                    1.0                   0.540890        19.0   \n",
       "...                  ...                        ...         ...   \n",
       "39639                1.0                   0.684783         9.0   \n",
       "39640                1.0                   0.885057         9.0   \n",
       "39641                1.0                   0.644128        24.0   \n",
       "39642                1.0                   0.692661        10.0   \n",
       "39643                1.0                   0.846154         1.0   \n",
       "\n",
       "        num_self_hrefs   num_imgs   num_videos   average_token_length  \\\n",
       "0                  2.0        1.0          0.0               4.680365   \n",
       "1                  1.0        1.0          0.0               4.913725   \n",
       "2                  1.0        1.0          0.0               4.393365   \n",
       "3                  0.0        1.0          0.0               4.404896   \n",
       "4                 19.0       20.0          0.0               4.682836   \n",
       "...                ...        ...          ...                    ...   \n",
       "39639              7.0        1.0          1.0               4.523121   \n",
       "39640              7.0        3.0         48.0               4.405488   \n",
       "39641              1.0       12.0          1.0               5.076923   \n",
       "39642              1.0        1.0          0.0               4.975073   \n",
       "39643              1.0        0.0          2.0               4.471338   \n",
       "\n",
       "        num_keywords   data_channel_is_lifestyle  \\\n",
       "0                5.0                         0.0   \n",
       "1                4.0                         0.0   \n",
       "2                6.0                         0.0   \n",
       "3                7.0                         0.0   \n",
       "4                7.0                         0.0   \n",
       "...              ...                         ...   \n",
       "39639            8.0                         0.0   \n",
       "39640            7.0                         0.0   \n",
       "39641            8.0                         0.0   \n",
       "39642            5.0                         0.0   \n",
       "39643            4.0                         0.0   \n",
       "\n",
       "        data_channel_is_entertainment   data_channel_is_bus  \\\n",
       "0                                 1.0                   0.0   \n",
       "1                                 0.0                   1.0   \n",
       "2                                 0.0                   1.0   \n",
       "3                                 1.0                   0.0   \n",
       "4                                 0.0                   0.0   \n",
       "...                               ...                   ...   \n",
       "39639                             0.0                   0.0   \n",
       "39640                             0.0                   0.0   \n",
       "39641                             0.0                   0.0   \n",
       "39642                             0.0                   0.0   \n",
       "39643                             1.0                   0.0   \n",
       "\n",
       "        data_channel_is_socmed   data_channel_is_tech   data_channel_is_world  \\\n",
       "0                          0.0                    0.0                     0.0   \n",
       "1                          0.0                    0.0                     0.0   \n",
       "2                          0.0                    0.0                     0.0   \n",
       "3                          0.0                    0.0                     0.0   \n",
       "4                          0.0                    1.0                     0.0   \n",
       "...                        ...                    ...                     ...   \n",
       "39639                      0.0                    1.0                     0.0   \n",
       "39640                      1.0                    0.0                     0.0   \n",
       "39641                      0.0                    0.0                     0.0   \n",
       "39642                      0.0                    0.0                     1.0   \n",
       "39643                      0.0                    0.0                     0.0   \n",
       "\n",
       "        kw_min_min   kw_max_min   kw_avg_min  \n",
       "0              0.0          0.0        0.000  \n",
       "1              0.0          0.0        0.000  \n",
       "2              0.0          0.0        0.000  \n",
       "3              0.0          0.0        0.000  \n",
       "4              0.0          0.0        0.000  \n",
       "...            ...          ...          ...  \n",
       "39639         -1.0        671.0      173.125  \n",
       "39640         -1.0        616.0      184.000  \n",
       "39641         -1.0        691.0      168.250  \n",
       "39642         -1.0          0.0       -1.000  \n",
       "39643         -1.0         97.0       23.500  \n",
       "\n",
       "[39644 rows x 20 columns]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:42:15.004582Z",
     "start_time": "2025-10-02T08:38:29.419525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import FIRM.base.operators.implications as implications\n",
    "import FIRM.base.operators.tnorms as tnorms\n",
    "I = lambda x, y: 1 - x + x * (y**0.01)\n",
    "T = lambda x, y: np.maximum(x + y - 1, 0)\n",
    "#I = implications.ImplicationsExamples.get_fuzzy_implication(implications.ImplicationsExamples.IGNORE)\n",
    "#T = tnorms.TnormsExamples.get_tnorm(tnorms.TnormsExamples.PRODUCT)\n",
    "rules = AARFI(dataset, fuzzy_dataset, T, I, min_cov=0.2, min_supp=0.2, min_conf=0.7, max_feat=3)\n",
    "measures = rules.measures(fuzzy_dataset)\n",
    "measures"
   ],
   "id": "8c92f9dbb2d0086d",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\base\\ct_fuzzy_rule.py:65\u001B[0m, in \u001B[0;36mCRFuzzyRule._get_membership_vector\u001B[1;34m(data, feature_idx, ling_idx, fuzzy_data, cache, dtype, chunk_size)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     vals \u001B[38;5;241m=\u001B[39m \u001B[43mmu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mastype(dtype)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\base\\fuzzy_set.py:10\u001B[0m, in \u001B[0;36mFuzzySet.__call__\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: \u001B[38;5;28mfloat\u001B[39m):\n\u001B[1;32m---> 10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mem_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\base\\membership_function.py:8\u001B[0m, in \u001B[0;36mMF.__call__\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: \u001B[38;5;28mfloat\u001B[39m):\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmin\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m))\n",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\base\\membership_function.py:44\u001B[0m, in \u001B[0;36mTriangularMF._execute\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_execute\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_b:\n\u001B[0;32m     45\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_a \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_b:\n",
      "\u001B[1;31mValueError\u001B[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\base\\ct_fuzzy_rule.py:73\u001B[0m, in \u001B[0;36mCRFuzzyRule._get_membership_vector\u001B[1;34m(data, feature_idx, ling_idx, fuzzy_data, cache, dtype, chunk_size)\u001B[0m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 73\u001B[0m     out[s:e] \u001B[38;5;241m=\u001B[39m \u001B[43mmu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m[\u001B[49m\u001B[43ms\u001B[49m\u001B[43m:\u001B[49m\u001B[43me\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# try vector input per chunk\u001B[39;00m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\base\\fuzzy_set.py:10\u001B[0m, in \u001B[0;36mFuzzySet.__call__\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: \u001B[38;5;28mfloat\u001B[39m):\n\u001B[1;32m---> 10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mem_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\base\\membership_function.py:8\u001B[0m, in \u001B[0;36mMF.__call__\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: \u001B[38;5;28mfloat\u001B[39m):\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmin\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m))\n",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\base\\membership_function.py:44\u001B[0m, in \u001B[0;36mTriangularMF._execute\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_execute\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_b:\n\u001B[0;32m     45\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_a \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_b:\n",
      "\u001B[1;31mValueError\u001B[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m T \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m x, y: np\u001B[38;5;241m.\u001B[39mmaximum(x \u001B[38;5;241m+\u001B[39m y \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m#I = implications.ImplicationsExamples.get_fuzzy_implication(implications.ImplicationsExamples.IGNORE)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m#T = tnorms.TnormsExamples.get_tnorm(tnorms.TnormsExamples.PRODUCT)\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m rules \u001B[38;5;241m=\u001B[39m \u001B[43mAARFI\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfuzzy_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mI\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_cov\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_supp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_conf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.7\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_feat\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m measures \u001B[38;5;241m=\u001B[39m rules\u001B[38;5;241m.\u001B[39mmeasures(fuzzy_dataset)\n\u001B[0;32m      9\u001B[0m measures\n",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\methods\\AARFI.py:206\u001B[0m, in \u001B[0;36mAARFI\u001B[1;34m(dataset, fuzzy_dataset, T, I, min_cov, min_supp, min_conf, max_feat)\u001B[0m\n\u001B[0;32m    203\u001B[0m         rule \u001B[38;5;241m=\u001B[39m CRFuzzyRule(lrule)\n\u001B[0;32m    204\u001B[0m         \u001B[38;5;66;03m# Use CRFuzzyRule's vectorized evaluation with membership cache to avoid recomputation\u001B[39;00m\n\u001B[0;32m    205\u001B[0m         \u001B[38;5;66;03m# If your CRFuzzyRule supports cache injection, pass it; else this call will re-evaluate.\u001B[39;00m\n\u001B[1;32m--> 206\u001B[0m         \u001B[43mrule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate_rule_database\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfuzzy_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mI\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    207\u001B[0m         rules\u001B[38;5;241m.\u001B[39mappend(rule)\n\u001B[0;32m    209\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m SetFuzzyRules(rules)\n",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\base\\ct_fuzzy_rule.py:108\u001B[0m, in \u001B[0;36mCRFuzzyRule.evaluate_rule_database\u001B[1;34m(self, data, fuzzy_data, T, I, cache, dtype)\u001B[0m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;66;03m# Antecedent vectors\u001B[39;00m\n\u001B[0;32m    106\u001B[0m ant_pairs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlrule[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    107\u001B[0m ant_vecs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m--> 108\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_membership_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mli\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfuzzy_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    109\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (fi, li) \u001B[38;5;129;01min\u001B[39;00m ant_pairs\n\u001B[0;32m    110\u001B[0m ]\n\u001B[0;32m    111\u001B[0m antecedents \u001B[38;5;241m=\u001B[39m _reduce_tnorm(ant_vecs, vT) \u001B[38;5;28;01mif\u001B[39;00m ant_vecs \u001B[38;5;28;01melse\u001B[39;00m np\u001B[38;5;241m.\u001B[39mones(\u001B[38;5;28mlen\u001B[39m(data), dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;66;03m# Consequent vector\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\base\\ct_fuzzy_rule.py:75\u001B[0m, in \u001B[0;36mCRFuzzyRule._get_membership_vector\u001B[1;34m(data, feature_idx, ling_idx, fuzzy_data, cache, dtype, chunk_size)\u001B[0m\n\u001B[0;32m     73\u001B[0m             out[s:e] \u001B[38;5;241m=\u001B[39m mu(col[s:e])  \u001B[38;5;66;03m# try vector input per chunk\u001B[39;00m\n\u001B[0;32m     74\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m---> 75\u001B[0m             out[s:e] \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfromiter\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcol\u001B[49m\u001B[43m[\u001B[49m\u001B[43ms\u001B[49m\u001B[43m:\u001B[49m\u001B[43me\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcount\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43me\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     76\u001B[0m     vals \u001B[38;5;241m=\u001B[39m out\n\u001B[0;32m     78\u001B[0m cache[key] \u001B[38;5;241m=\u001B[39m vals\n",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\base\\ct_fuzzy_rule.py:75\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     73\u001B[0m             out[s:e] \u001B[38;5;241m=\u001B[39m mu(col[s:e])  \u001B[38;5;66;03m# try vector input per chunk\u001B[39;00m\n\u001B[0;32m     74\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m---> 75\u001B[0m             out[s:e] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfromiter((\u001B[43mmu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m col[s:e]), count\u001B[38;5;241m=\u001B[39me \u001B[38;5;241m-\u001B[39m s, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m     76\u001B[0m     vals \u001B[38;5;241m=\u001B[39m out\n\u001B[0;32m     78\u001B[0m cache[key] \u001B[38;5;241m=\u001B[39m vals\n",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\base\\fuzzy_set.py:10\u001B[0m, in \u001B[0;36mFuzzySet.__call__\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: \u001B[38;5;28mfloat\u001B[39m):\n\u001B[1;32m---> 10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mem_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\FIRM\\FIRM\\base\\membership_function.py:8\u001B[0m, in \u001B[0;36mMF.__call__\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: \u001B[38;5;28mfloat\u001B[39m):\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:05:49.571513Z",
     "start_time": "2025-10-01T15:05:49.414880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import FIRM.base.ct_fuzzy_rule as fuzzy_rule\n",
    "rule1 = fuzzy_rule.CRFuzzyRule([(2, 0), (1, 0)])\n",
    "rule2 = fuzzy_rule.CRFuzzyRule([(1, 0), (2, 0)])\n",
    "rule1.evaluate_rule_database(dataset, fuzzy_dataset, T, I)\n",
    "rule2.evaluate_rule_database(dataset, fuzzy_dataset, T, I)\n",
    "print(rule1.sentence_rule(fuzzy_dataset))\n",
    "print(\"  Support:\", rule1.fsupport())\n",
    "print(\"  Confidence:\", rule1.fconfidence())\n",
    "\n",
    "print(rule2.sentence_rule(fuzzy_dataset))\n",
    "print(\"  Support:\", rule2.fsupport())\n",
    "print(\"  Confidence:\", rule2.fconfidence())"
   ],
   "id": "7e06c5095c53a5cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF ( HouseMedianAge IS L ) THEN Latitude IS L\n",
      "  Support: 0.16615977883338928\n",
      "  Confidence: 0.4448797546619245\n",
      "IF ( Latitude IS L ) THEN HouseMedianAge IS L\n",
      "  Support: 0.1868894100189209\n",
      "  Confidence: 0.4817239778529963\n"
     ]
    }
   ],
   "execution_count": 298
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:05:49.655679Z",
     "start_time": "2025-10-01T15:05:49.643193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract measures\n",
    "num_rules = len(measures['num_features'])\n",
    "fcoverage_mean, fcoverage_std = np.mean(measures['fcoverage']), np.std(measures['fcoverage'])\n",
    "fsupport_mean, fsupport_std = np.mean(measures['fsupport']), np.std(measures['fsupport'])\n",
    "fconfidence_mean, fconfidence_std = np.mean(measures['fconfidence']), np.std(measures['fconfidence'])\n",
    "fwracc_mean, fwracc_std = np.mean(measures['fwracc']), np.std(measures['fwracc'])\n",
    "\n",
    "# Print results\n",
    "print('num rules:', num_rules)\n",
    "print(f'fcoverage: mean={fcoverage_mean:.4f}, std={fcoverage_std:.4f}')\n",
    "print(f'fsupport: mean={fsupport_mean:.4f}, std={fsupport_std:.4f}')\n",
    "print(f'fconfidence: mean={fconfidence_mean:.4f}, std={fconfidence_std:.4f}')"
   ],
   "id": "689a76383d23f04b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num rules: 36\n",
      "fcoverage: mean=0.3381, std=0.0575\n",
      "fsupport: mean=0.3021, std=0.0512\n",
      "fconfidence: mean=0.8972, std=0.0757\n"
     ]
    }
   ],
   "execution_count": 299
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:42:26.802481Z",
     "start_time": "2025-10-02T08:42:19.915039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = dataset.copy()\n",
    "\n",
    "for i in range(len(fuzzy_dataset.fv_list)):\n",
    "    labels = getattr(fuzzy_dataset.fv_list[i], \"get_labels\")\n",
    "    labels = labels() if callable(labels) else labels\n",
    "    \n",
    "    data[dataset.columns[i]] = dataset[dataset.columns[i]].map(\n",
    "        lambda x: fuzzy_dataset.fv_list[i].eval_max_fuzzy_set(x)\n",
    "    )\n",
    "\n",
    "df_encoded = pd.get_dummies(data,columns=data.columns)"
   ],
   "id": "77c5b4f117c8e05d",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T08:43:49.427407Z",
     "start_time": "2025-10-02T08:42:30.479390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "df = apriori(df_encoded, min_support=0.2, use_colnames=True, verbose=1)\n",
    "df_ar = association_rules(df, metric=\"confidence\", min_threshold=0.7)\n",
    "# Keep only rules with <=3 items in antecedent and <=1 in consequent\n",
    "df_rules_filtered = df_ar[\n",
    "    (df_ar['antecedents'].apply(len) <= 3) &\n",
    "    (df_ar['consequents'].apply(len) <= 1)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "rules_sorted = df_rules_filtered.sort_values(by=\"confidence\", ascending=False).reset_index(drop=True)\n",
    "rules_sorted\n"
   ],
   "id": "99cc693621a94251",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 13 combinations | Sampling itemset size 131210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raquel\\PycharmProjects\\FIRM\\.venv\\Lib\\site-packages\\mlxtend\\frequent_patterns\\association_rules.py:186: RuntimeWarning: invalid value encountered in divide\n",
      "  cert_metric = np.where(certainty_denom == 0, 0, certainty_num / certainty_denom)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                             antecedents  \\\n",
       "0                                    ( n_tokens_title_H)   \n",
       "1      ( num_videos_L,  num_hrefs_L,  data_channel_is...   \n",
       "2      ( num_hrefs_L,  average_token_length_L,  data_...   \n",
       "3      ( num_videos_L,  num_hrefs_L,  average_token_l...   \n",
       "4      ( data_channel_is_tech_L,  num_hrefs_L,  avera...   \n",
       "...                                                  ...   \n",
       "14737  ( n_tokens_content_L,  data_channel_is_socmed_...   \n",
       "14738  ( data_channel_is_tech_L,  n_tokens_content_L,...   \n",
       "14739  ( n_tokens_content_L,  data_channel_is_world_L...   \n",
       "14740  ( n_tokens_content_L,  kw_min_min_L,  n_non_st...   \n",
       "14741  ( n_tokens_content_L,  num_imgs_L,  n_non_stop...   \n",
       "\n",
       "                              consequents  antecedent support  \\\n",
       "0                           ( num_imgs_L)            0.294572   \n",
       "1      ( data_channel_is_entertainment_L)            0.429422   \n",
       "2                         ( num_videos_L)            0.204823   \n",
       "3               ( data_channel_is_tech_L)            0.204823   \n",
       "4                         ( num_videos_L)            0.204823   \n",
       "...                                   ...                 ...   \n",
       "14737                      ( num_hrefs_L)            0.338185   \n",
       "14738                      ( num_hrefs_L)            0.338185   \n",
       "14739                      ( num_hrefs_L)            0.338185   \n",
       "14740                      ( num_hrefs_L)            0.338185   \n",
       "14741                      ( num_hrefs_L)            0.338185   \n",
       "\n",
       "       consequent support   support  confidence      lift  representativity  \\\n",
       "0                1.000000  0.294572    1.000000  1.000000               1.0   \n",
       "1                1.000000  0.429422    1.000000  1.000000               1.0   \n",
       "2                1.000000  0.204823    1.000000  1.000000               1.0   \n",
       "3                1.000000  0.204823    1.000000  1.000000               1.0   \n",
       "4                1.000000  0.204823    1.000000  1.000000               1.0   \n",
       "...                   ...       ...         ...       ...               ...   \n",
       "14737            0.429422  0.240440    0.710972  1.655649               1.0   \n",
       "14738            0.429422  0.240440    0.710972  1.655649               1.0   \n",
       "14739            0.429422  0.240440    0.710972  1.655649               1.0   \n",
       "14740            0.429422  0.240440    0.710972  1.655649               1.0   \n",
       "14741            0.429422  0.240440    0.710972  1.655649               1.0   \n",
       "\n",
       "       leverage  conviction  zhangs_metric   jaccard  certainty  kulczynski  \n",
       "0      0.000000         inf       0.000000  0.294572   0.000000    0.647286  \n",
       "1      0.000000         inf       0.000000  0.429422   0.000000    0.714711  \n",
       "2      0.000000         inf       0.000000  0.204823   0.000000    0.602411  \n",
       "3      0.000000         inf       0.000000  0.204823   0.000000    0.602411  \n",
       "4      0.000000         inf       0.000000  0.204823   0.000000    0.602411  \n",
       "...         ...         ...            ...       ...        ...         ...  \n",
       "14737  0.095216    1.974127       0.598365  0.456098   0.493447    0.635444  \n",
       "14738  0.095216    1.974127       0.598365  0.456098   0.493447    0.635444  \n",
       "14739  0.095216    1.974127       0.598365  0.456098   0.493447    0.635444  \n",
       "14740  0.095216    1.974127       0.598365  0.456098   0.493447    0.635444  \n",
       "14741  0.095216    1.974127       0.598365  0.456098   0.493447    0.635444  \n",
       "\n",
       "[14742 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>representativity</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>certainty</th>\n",
       "      <th>kulczynski</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>( n_tokens_title_H)</td>\n",
       "      <td>( num_imgs_L)</td>\n",
       "      <td>0.294572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.294572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.647286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>( num_videos_L,  num_hrefs_L,  data_channel_is...</td>\n",
       "      <td>( data_channel_is_entertainment_L)</td>\n",
       "      <td>0.429422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.429422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>( num_hrefs_L,  average_token_length_L,  data_...</td>\n",
       "      <td>( num_videos_L)</td>\n",
       "      <td>0.204823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.204823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.602411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>( num_videos_L,  num_hrefs_L,  average_token_l...</td>\n",
       "      <td>( data_channel_is_tech_L)</td>\n",
       "      <td>0.204823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.204823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.602411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>( data_channel_is_tech_L,  num_hrefs_L,  avera...</td>\n",
       "      <td>( num_videos_L)</td>\n",
       "      <td>0.204823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.204823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.602411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14737</th>\n",
       "      <td>( n_tokens_content_L,  data_channel_is_socmed_...</td>\n",
       "      <td>( num_hrefs_L)</td>\n",
       "      <td>0.338185</td>\n",
       "      <td>0.429422</td>\n",
       "      <td>0.240440</td>\n",
       "      <td>0.710972</td>\n",
       "      <td>1.655649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095216</td>\n",
       "      <td>1.974127</td>\n",
       "      <td>0.598365</td>\n",
       "      <td>0.456098</td>\n",
       "      <td>0.493447</td>\n",
       "      <td>0.635444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14738</th>\n",
       "      <td>( data_channel_is_tech_L,  n_tokens_content_L,...</td>\n",
       "      <td>( num_hrefs_L)</td>\n",
       "      <td>0.338185</td>\n",
       "      <td>0.429422</td>\n",
       "      <td>0.240440</td>\n",
       "      <td>0.710972</td>\n",
       "      <td>1.655649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095216</td>\n",
       "      <td>1.974127</td>\n",
       "      <td>0.598365</td>\n",
       "      <td>0.456098</td>\n",
       "      <td>0.493447</td>\n",
       "      <td>0.635444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14739</th>\n",
       "      <td>( n_tokens_content_L,  data_channel_is_world_L...</td>\n",
       "      <td>( num_hrefs_L)</td>\n",
       "      <td>0.338185</td>\n",
       "      <td>0.429422</td>\n",
       "      <td>0.240440</td>\n",
       "      <td>0.710972</td>\n",
       "      <td>1.655649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095216</td>\n",
       "      <td>1.974127</td>\n",
       "      <td>0.598365</td>\n",
       "      <td>0.456098</td>\n",
       "      <td>0.493447</td>\n",
       "      <td>0.635444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14740</th>\n",
       "      <td>( n_tokens_content_L,  kw_min_min_L,  n_non_st...</td>\n",
       "      <td>( num_hrefs_L)</td>\n",
       "      <td>0.338185</td>\n",
       "      <td>0.429422</td>\n",
       "      <td>0.240440</td>\n",
       "      <td>0.710972</td>\n",
       "      <td>1.655649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095216</td>\n",
       "      <td>1.974127</td>\n",
       "      <td>0.598365</td>\n",
       "      <td>0.456098</td>\n",
       "      <td>0.493447</td>\n",
       "      <td>0.635444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14741</th>\n",
       "      <td>( n_tokens_content_L,  num_imgs_L,  n_non_stop...</td>\n",
       "      <td>( num_hrefs_L)</td>\n",
       "      <td>0.338185</td>\n",
       "      <td>0.429422</td>\n",
       "      <td>0.240440</td>\n",
       "      <td>0.710972</td>\n",
       "      <td>1.655649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095216</td>\n",
       "      <td>1.974127</td>\n",
       "      <td>0.598365</td>\n",
       "      <td>0.456098</td>\n",
       "      <td>0.493447</td>\n",
       "      <td>0.635444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14742 rows × 14 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:05:52.746142Z",
     "start_time": "2025-10-01T15:05:52.736082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of rules (rows)\n",
    "num_rules = len(rules_sorted)\n",
    "\n",
    "# Compute mean and std only for support and confidence\n",
    "support_mean, support_std = rules_sorted['support'].mean(), rules_sorted['support'].std()\n",
    "confidence_mean, confidence_std = rules_sorted['confidence'].mean(), rules_sorted['confidence'].std()\n",
    "\n",
    "# Print results\n",
    "print(f'num rules: {num_rules}')\n",
    "print(f'support: mean={support_mean:.4f}, std={support_std:.4f}')\n",
    "print(f'confidence: mean={confidence_mean:.4f}, std={confidence_std:.4f}')\n"
   ],
   "id": "f6640f7ce710f8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num rules: 89\n",
      "support: mean=0.3019, std=0.0521\n",
      "confidence: mean=0.9151, std=0.0931\n"
     ]
    }
   ],
   "execution_count": 302
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:05:52.886793Z",
     "start_time": "2025-10-01T15:05:52.877753Z"
    }
   },
   "cell_type": "code",
   "source": "rules_sorted.iloc[0]['antecedents']",
   "id": "b3ac897beb52b72a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'Latitude_L', 'Longitude_H'})"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 303
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:05:53.014745Z",
     "start_time": "2025-10-01T15:05:52.978149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def _tokens_from_group(group):\n",
    "    \"\"\"Return a list of 'Var_Label' tokens from frozenset/set/list/tuple or string.\"\"\"\n",
    "    if group is None or (isinstance(group, float) and math.isnan(group)):\n",
    "        return []\n",
    "    if isinstance(group, (set, frozenset, list, tuple)):\n",
    "        return [str(x).strip() for x in group if str(x).strip()]\n",
    "    if isinstance(group, str):\n",
    "        s = group.strip()\n",
    "        if not s:\n",
    "            return []\n",
    "        if s.startswith(\"(\") and s.endswith(\")\"):\n",
    "            s = s[1:-1].strip()\n",
    "        return [t.strip() for t in s.split(\",\")] if \",\" in s else [s]\n",
    "    return [str(group).strip()]\n",
    "\n",
    "def _build_var_and_label_maps(dataset_columns, fuzzy_dataset):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      var_to_idx: {var_name -> position i}\n",
    "      label_maps: {var_name -> {label_string -> label_index}}\n",
    "    Labels come from fuzzy_dataset.fv_list[i].get_labels()\n",
    "    \"\"\"\n",
    "    cols_list = list(dataset_columns.tolist()) if hasattr(dataset_columns, \"tolist\") else list(dataset_columns)\n",
    "    var_to_idx = {name: i for i, name in enumerate(cols_list)}\n",
    "\n",
    "    label_maps = {}\n",
    "    for var_name, i in var_to_idx.items():\n",
    "        # CALL the method to get the actual label list\n",
    "        labels = list(fuzzy_dataset.fv_list[i].get_labels)\n",
    "        # keep original strings; also add a case-insensitive shim\n",
    "        per_var = {str(lab): j for j, lab in enumerate(labels)}\n",
    "        label_maps[var_name] = per_var\n",
    "    return var_to_idx, label_maps\n",
    "\n",
    "def _resolve_label_idx(var: str, lab: str, label_maps: dict) -> int:\n",
    "    \"\"\"\n",
    "    Map a label string to its index using label_maps[var].\n",
    "    Tries exact, then case-insensitive exact, then first-letter (if unique).\n",
    "    \"\"\"\n",
    "    per_var = label_maps[var]\n",
    "    if lab in per_var:\n",
    "        return per_var[lab]\n",
    "    # case-insensitive exact\n",
    "    for k in per_var.keys():\n",
    "        if k.lower() == lab.lower():\n",
    "            return per_var[k]\n",
    "    # First-letter fallback, only if unique\n",
    "    fl = lab[:1].lower()\n",
    "    candidates = [name for name in per_var.keys() if name[:1].lower() == fl]\n",
    "    if len(candidates) == 1:\n",
    "        return per_var[candidates[0]]\n",
    "    raise KeyError(f\"Unknown label {lab!r} for variable {var!r}. Known labels: {list(per_var.keys())}\")\n",
    "\n",
    "def _pair_from_token(token: str, var_to_idx: dict, label_maps: dict) -> tuple[int, int]:\n",
    "    \"\"\"Map 'Var_Label' -> (var_idx, label_idx) using dataset column order + fuzzy_dataset labels.\"\"\"\n",
    "    if \"_\" not in token:\n",
    "        raise ValueError(f\"Expected 'Var_Label', got: {token!r}\")\n",
    "    var, lab = token.rsplit(\"_\", 1)  # last underscore splits var from label\n",
    "    var = var.strip()\n",
    "    lab = lab.strip()\n",
    "    if var not in var_to_idx:\n",
    "        raise KeyError(f\"Variable {var!r} not found in dataset columns: {list(var_to_idx.keys())}\")\n",
    "    var_idx = var_to_idx[var]\n",
    "    lab_idx = _resolve_label_idx(var, lab, label_maps)\n",
    "    return (var_idx, lab_idx)\n",
    "\n",
    "def _group_to_pairs(group, var_to_idx, label_maps):\n",
    "    tokens = _tokens_from_group(group)\n",
    "    pairs = [_pair_from_token(t, var_to_idx, label_maps) for t in tokens]\n",
    "    # Deterministic order (since sets/frozensets are unordered)\n",
    "    pairs.sort(key=lambda x: x[0])\n",
    "    return pairs\n",
    "\n",
    "def _pick_consequent(con_pairs):\n",
    "    \"\"\"\n",
    "    Choose one consequent tuple from con_pairs.\n",
    "    - If exactly one, use it.\n",
    "    - If multiple, pick the one with the highest variable index (you can change to lowest).\n",
    "    \"\"\"\n",
    "    if not con_pairs:\n",
    "        raise ValueError(\"Rule has no consequent.\")\n",
    "    if len(con_pairs) == 1:\n",
    "        return con_pairs[0]\n",
    "    # pick by highest var index (change to min if you prefer)\n",
    "    return max(con_pairs, key=lambda x: x[0])\n",
    "\n",
    "def df_to_crfuzzyrules(df: pd.DataFrame, dataset_columns, fuzzy_dataset):\n",
    "    \"\"\"\n",
    "    Build CRFuzzyRule objects from df['antecedents'] and df['consequents'].\n",
    "    Each CRFuzzyRule receives [*antecedents, consequent] (consequent appended last).\n",
    "    Returns (rules, consequents_as_singleton_lists) to keep backward compatibility.\n",
    "    \"\"\"\n",
    "    var_to_idx, label_maps = _build_var_and_label_maps(dataset_columns, fuzzy_dataset)\n",
    "\n",
    "\n",
    "    rules, consequents = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        ant_pairs = _group_to_pairs(row[\"antecedents\"], var_to_idx, label_maps)\n",
    "        con_pairs = _group_to_pairs(row[\"consequents\"], var_to_idx, label_maps)\n",
    "        c = _pick_consequent(con_pairs)\n",
    "        combined = ant_pairs + [c]          # consequent at the end\n",
    "        rules.append(fuzzy_rule.CRFuzzyRule(combined))\n",
    "        consequents.append([c])             # keep a reference to the chosen consequent\n",
    "    return rules, consequents\n",
    "\n",
    "# ---------------------------\n",
    "# Usage (unchanged for your call site)\n",
    "dataset_columns = dataset.columns\n",
    "rules_crisp, cons = df_to_crfuzzyrules(rules_sorted, dataset_columns, fuzzy_dataset)"
   ],
   "id": "466d5d10484cbe87",
   "outputs": [],
   "execution_count": 304
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:05:53.065540Z",
     "start_time": "2025-10-01T15:05:53.061015Z"
    }
   },
   "cell_type": "code",
   "source": "from FIRM.base.ct_set_fuzzy_rules import SetFuzzyRules",
   "id": "8970ce16778cb8f7",
   "outputs": [],
   "execution_count": 305
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T15:05:53.149692Z",
     "start_time": "2025-10-01T15:05:53.115263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rules1 = SetFuzzyRules(rules.rule_list[:max(1, math.ceil(0.20 * len(rules.rule_list)))])\n",
    "rules2 = SetFuzzyRules(rules_crisp[:max(1, math.ceil(0.20 * len(rules_crisp)))])\n",
    "rules1.jaccard_similarity(rules2)"
   ],
   "id": "25cdca695168bd3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 306
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
