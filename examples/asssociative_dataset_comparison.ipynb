{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import FIRM.base.operators.implications as implications\n",
    "import FIRM.base.operators.tnorms as tnorms\n",
    "import FIRM.base.fuzzy_data as fuzzy_data\n",
    "from FIRM.methods.AARFI import AARFI"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "impl_operators = [implications.ImplicationsExamples.get_fuzzy_implication(implications.ImplicationsExamples.IGNORE),\n",
    "                  implications.ImplicationsExamples.get_fuzzy_implication(implications.ImplicationsExamples.LUKASIEWICZ),\n",
    "                  lambda x, y: implications.ImplicationsExamples.get_fuzzy_implication(implications.ImplicationsExamples.CH10)(x,y,float(0.01)),\n",
    "                  lambda x, y: implications.ImplicationsExamples.get_fuzzy_implication(implications.ImplicationsExamples.KSS)(x, y, float(-10))]\n",
    "tnorms_operators = [tnorms.TnormsExamples.get_tnorm(tnorms.TnormsExamples.PRODUCT),\n",
    "                    tnorms.TnormsExamples.get_tnorm(tnorms.TnormsExamples.LUKASIEWICZ),\n",
    "                    tnorms.TnormsExamples.get_tnorm(tnorms.TnormsExamples.PRODUCT),\n",
    "                    lambda x, y: tnorms.TnormsExamples.get_tnorm(tnorms.TnormsExamples.SCHWEIZER_SKLAR)(x, y,float(-10))]"
   ],
   "id": "b54c1ee7a27f3491",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_df(df):\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].dropna().unique()  # Get unique values, excluding NaN\n",
    "        if len(unique_values) < 15:\n",
    "            df[col] = df[col].astype('object')  # Convert to boolean\n",
    "        else:\n",
    "            df[col] = df[col].astype('float64')  # Convert to categorical for other binary cases\n",
    "    return df"
   ],
   "id": "ed60a3248249dad7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "datasets = ['abalone.csv','iris.csv','wdbc.csv','magic.csv','vehicle.csv']",
   "id": "4add2d7d4a0bbf44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n_datasets = len(datasets)\n",
    "n_operators = len(impl_operators)\n",
    "\n",
    "results = [[0 for _ in range(n_datasets)] for _ in range(n_operators)]\n",
    "\n",
    "# Open a CSV file to write the results\n",
    "with open('results.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    writer.writerow(['Operator', 'Dataset', 'Num Rules', 'Fcoverage', 'Fsupport', 'Fconfidence','FWRAcc'])\n",
    "\n",
    "    for idx_op in range(n_operators):\n",
    "        print('Operator: ' + str(idx_op))\n",
    "        I = impl_operators[idx_op]\n",
    "        T = tnorms_operators[idx_op]\n",
    "        for idx_dat in range(n_datasets):\n",
    "            print('Dataset: ' + str(datasets[idx_dat]))\n",
    "            name_dataset = datasets[idx_dat]\n",
    "            dataset = process_df(pd.read_csv('../assets/' + name_dataset, sep=','))\n",
    "            fuzzy_dataset = fuzzy_data.FuzzyDataQuantiles(name_dataset, dataset, 3, ['L', 'M', 'H'])\n",
    "            rules = AARFI(dataset, fuzzy_dataset, T, I, min_cov=0.3, min_supp=0.3, min_conf=0.8, max_feat=3)\n",
    "            measures = rules.measures(fuzzy_dataset)\n",
    "            \n",
    "            # Extract measures\n",
    "            num_rules = len(measures['num_features'])\n",
    "            fcoverage = np.mean(measures['fcoverage'])\n",
    "            fsupport = np.mean(measures['fsupport'])\n",
    "            fconfidence = np.mean(measures['fconfidence'])\n",
    "            fwracc = np.mean(measures['fwracc'])\n",
    "            \n",
    "            print('num rules: ' + str(len(measures['num_features'])))\n",
    "            print('fcoverage: ' + str(np.mean(measures['fcoverage'])))\n",
    "            print('fsupport: ' + str(np.mean(measures['fsupport'])))\n",
    "            print('fconfidence: ' + str(np.mean(measures['fconfidence'])))\n",
    "            print('fwracc: ' + str(np.mean(measures['fwracc'])))\n",
    "            \n",
    "            # Write the results to the CSV file\n",
    "            writer.writerow([idx_op, name_dataset, num_rules, fcoverage, fsupport, fconfidence,fwracc])\n",
    "            \n",
    "            # Store the rule list in the results matrix\n",
    "            results[idx_op][idx_dat] = rules.rule_list\n",
    "\n",
    "print(\"Results have been saved to 'results.csv'\")"
   ],
   "id": "1c5ad8b6e157ff6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from FIRM.base.ct_set_fuzzy_rules import SetFuzzyRules",
   "id": "7f6306b717527a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "M = np.ones((n_operators, n_operators))\n",
    "for i in range(0, n_operators):\n",
    "    for j in range(i + 1, n_operators):\n",
    "        diss_perc = []\n",
    "        for d in range(0, n_datasets):\n",
    "            rules1 = SetFuzzyRules(results[i][d][:]) \n",
    "            rules2 = SetFuzzyRules(results[j][d][:])\n",
    "            diss_perc = diss_perc + [rules1.jaccard_similarity(rules2)]\n",
    "        M[i][j] = round(np.mean(diss_perc),3)"
   ],
   "id": "e9518754a80a49a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data from the table\n",
    "data = {\n",
    "    \"(TP,IY)\": M[0],\n",
    "    \"(TLK,ILK)\": M[1],\n",
    "    \"(TP,ICλH)\": M[2],\n",
    "    \"(TSSλ,ISSλ)\": M[3]\n",
    "}\n",
    "\n",
    "# Row labels\n",
    "index = [\"(TP,IY)\", \"(TLK,ILK)\", \"(TP,ICλH)\", \"(TSSλ,ISSλ)\"]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "# Mask the upper triangle to show only non-redundant values\n",
    "mask = np.triu(np.ones_like(df, dtype=bool), k=1)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    df,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",  # Brighter colormap (options: \"viridis\", \"plasma\", \"magma\", \"inferno\")\n",
    "    fmt=\".2f\",  # Display two decimal places\n",
    "    linewidths=0.5,\n",
    "    mask=mask,  # Apply the mask to hide the upper triangle\n",
    "    cbar_kws={\"shrink\": 0.8}\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b22f229ddb38d268",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
